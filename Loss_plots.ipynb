{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f114fcb-39a6-4054-8a39-384f19017dab",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16dfe19d-15b4-4a20-899a-fd7adc8805f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5675f96-5799-4ced-86a1-45b18a36f4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2e6b4af-2f62-49bb-9f19-a259edf0c108",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "from torchvision import datasets, transforms\n",
    "# from pytorchcv.model_provider import get_model as ptcv_get_model # model\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1176eb20-c01b-45ae-baee-feaee79000e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from loss_landscape.my_pyhessian import hessian, utils# Hessian computation\n",
    "from loss_landscape.my_pyhessian.density_plot import get_esd_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5974c0de-9045-4bf1-8ab8-a0d1433fbdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from loss_landscape.plot_2D import plot_2d_contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdd2682c-4386-4309-87d6-c381f51624e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys; sys.path.append(\"..\")\n",
    "from models.smooth_cross_entropy import mean_smooth_crossentropy\n",
    "from models.wide_res_net import WideResNet\n",
    "from models.attention_gru import AttentionGru\n",
    "from models.gcn import GCN\n",
    "\n",
    "from DatasetClass.cifar import Cifar\n",
    "from DatasetClass.imdb import Imdb\n",
    "from DatasetClass.TUD import GraphDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295d632c-5fee-4547-bdcd-d22afbf0c094",
   "metadata": {
    "tags": []
   },
   "source": [
    "# WideResNet for Cifar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677eeb00-17e2-4e85-98d8-84f0ee31e5c2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Loss landscape plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd410734-a960-48d0-8565-0ffa87d98526",
   "metadata": {
    "tags": []
   },
   "source": [
    "### With SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d4eeff-72c4-4fad-b8c5-26c4b53b3b39",
   "metadata": {
    "tags": []
   },
   "source": [
    "Generate surface file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812a08f5-0693-4038-879e-40f23754b764",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run plot_surface.py for trained model\n",
    "# !python plot_surface.py --model WideResNet --dataset cifar10 --x=-1:1:2 --y=-1:1:2 --model_file to_plot/model_cifar_SGD.pt --dir_type weights --xnorm filter --xignore biasbn --ynorm filter --yignore biasbn --plot --percentage=0.3 --batch_size=128 --loss_name smooth_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68f58e0-4b6a-4e29-bff8-4ba9e6dc6ab4",
   "metadata": {
    "tags": []
   },
   "source": [
    "Generate plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96d134e2-8962-4dbb-beea-11a9cd581314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "plot_2d_contour\n",
      "------------------------------------------------------------------\n",
      "len(xcoordinates): 5   len(ycoordinates): 5\n",
      "[[19.47184278  4.94447712  6.3274922  10.84011077 38.55445198]\n",
      " [ 6.52683822  2.74590339  3.3255251   3.25660324 12.8048792 ]\n",
      " [ 3.97482543  1.80651281  0.46783798  1.99040413  5.71666521]\n",
      " [ 4.86280387  2.75262686  1.93810351  2.42843889  6.8996155 ]\n",
      " [24.73039846  9.45652653  5.2411354   3.49049795 11.69184616]]\n"
     ]
    }
   ],
   "source": [
    "surf_file = 'to_plot/model_cifar_SGD.pt_weights_xignore=biasbn_xnorm=filter_yignore=biasbn_ynorm=filter.h5_[-1.0,1.0,5]x[-1.0,1.0,5].h5'\n",
    "\n",
    "plot_2d_contour(surf_file, 'train_loss', 0.1, 10, 0.5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9c840f-4a65-4ab9-8af0-c479d3dc9d4e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### With SAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6958ffb-a7ed-419d-9222-7c1e2b07a478",
   "metadata": {
    "tags": []
   },
   "source": [
    "Generate surface file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c1bb9c-652b-47f5-9460-ea5fa5640a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run plot_surface.py for trained model\n",
    "# !python plot_surface.py --model WideResNet --dataset cifar10 --x=-1:1:2 --y=-1:1:2 --model_file to_plot/model_cifar_SAM_rho1.pt --dir_type weights --xnorm filter --xignore biasbn --ynorm filter --yignore biasbn --plot --percentage=0.3 --batch_size=128 --loss_name smooth_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f3c3bf-b893-4006-8e04-6773868218eb",
   "metadata": {},
   "source": [
    "Generate plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8ab4aa0-dc79-412b-a449-3180bcc69347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "plot_2d_contour\n",
      "------------------------------------------------------------------\n",
      "len(xcoordinates): 5   len(ycoordinates): 5\n",
      "[[2.40649363 2.45352721 2.37080363 2.33494368 3.27218929]\n",
      " [2.11266517 1.72538848 1.35355867 1.86808758 2.42179902]\n",
      " [1.96148256 1.27078478 0.87594321 1.30209623 2.05305649]\n",
      " [2.82968777 1.60050254 1.09351784 1.46998333 1.97798065]\n",
      " [7.75504659 2.75616385 1.72724978 1.85543291 2.30363232]]\n"
     ]
    }
   ],
   "source": [
    "surf_file = 'to_plot/model_cifar_halfSAM_rho05.pt_weights_xignore=biasbn_xnorm=filter_yignore=biasbn_ynorm=filter.h5_[-1.0,1.0,5]x[-1.0,1.0,5].h5'\n",
    "\n",
    "plot_2d_contour(surf_file, 'train_loss', 0.1, 10, 0.5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b751462-9873-4455-b5a6-0ffa29e1f83c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Eigenvalues of hessian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6c05eb-51ae-45b0-9180-b967392dadc8",
   "metadata": {},
   "source": [
    "Load trained model and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f0d2138-531c-4d85-95cb-7482057c5ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'WideResNet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5057056e-58e2-43f2-af64-16ec4722f3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# get dataset \n",
    "dataset = Cifar(0.3, 128, 2)\n",
    "trainloader, testloader = dataset.train, dataset.test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f091f10-2ee7-45fa-902c-12c3fa509027",
   "metadata": {},
   "source": [
    "Extract batches of data for computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a15447d-b7cd-4e3c-a2d0-b13de71e5504",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batches = 1\n",
    "\n",
    "inputs = None\n",
    "targets = None\n",
    "\n",
    "for ind, (data, tar) in enumerate(trainloader):\n",
    "    if inputs is None:\n",
    "        inputs = data\n",
    "        targets = tar\n",
    "    elif inputs is not None and ind < num_batches:\n",
    "        inputs = torch.cat((inputs, data), 0)\n",
    "        targets = torch.cat((targets, tar))\n",
    "    else:\n",
    "        break\n",
    "\n",
    "[print(inputs.size(), targets.size()) if targets is not None else print(inputs.size())]\n",
    "\n",
    "# we use cuda to make the computation fast\n",
    "# model = model.cuda()\n",
    "# inputs, targets = inputs.cuda(), targets.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d43192a-2f18-48ec-8b05-d79338c52a4a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### With SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b40de132-11c4-4c97-8ee9-8d53c3723cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stored = torch.load('to_plot/model_cifar_SGD.pt', map_location=lambda storage, loc: storage)\n",
    "\n",
    "model = WideResNet(8, 2, 0.0, in_channels=3, labels=10)\n",
    "\n",
    "if 'state_dict' in stored.keys():\n",
    "    model.load_state_dict(stored['state_dict'])\n",
    "else:\n",
    "    model.load_state_dict(stored)\n",
    "model.eval()\n",
    "\n",
    "criterion = mean_smooth_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a7fff5-dc75-4e42-94df-ef69f0b28403",
   "metadata": {},
   "source": [
    "Create the hessian computation module and compute eigenvalue density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e306237e-a4f9-425e-bcff-662402863331",
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_file_name = 'wideresnet_sgd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5d7d6c75-45d2-4967-8ceb-3359e47edda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    density_eigen = np.load('Eigenvalues/'+eig_file_name+'_eigen.npy')\n",
    "    density_weight = np.load('Eigenvalues/'+eig_file_name+'_weight.npy')\n",
    "except:\n",
    "    hessian_comp = hessian(model, criterion, data=(inputs, targets), cuda=False, model_name = model_name)\n",
    "    density_eigen, density_weight = hessian_comp.density(iter=100, n_v=1)\n",
    "    np.save('Eigenvalues/'+eig_file_name+'_eigen.npy', density_eigen)\n",
    "    np.save('Eigenvalues/'+eig_file_name+'_weight.npy', density_weight)\n",
    "    \n",
    "get_esd_plot(density_eigen, density_weight,'plots/eig_'+eig_file_name+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe264016-eef7-41df-b718-60cd60a1677d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### With SAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c8f1ee07-5d7e-4469-b836-2b2dfcf9fcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "stored = torch.load('to_plot/model_cifar_halfSAM_rho0.5.pt', map_location=lambda storage, loc: storage)\n",
    "\n",
    "model = WideResNet(8, 2, 0.0, in_channels=3, labels=10)\n",
    "\n",
    "if 'state_dict' in stored.keys():\n",
    "    model.load_state_dict(stored['state_dict'])\n",
    "else:\n",
    "    model.load_state_dict(stored)\n",
    "model.eval()\n",
    "\n",
    "criterion = mean_smooth_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94e4ac6-f68f-41d4-8b22-f3747f3efb52",
   "metadata": {},
   "source": [
    "Create the hessian computation module and compute eigenvalue density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b80389-9fa5-4a6f-bc67-01fd105b7722",
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_file_name = 'wideresnet_sam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9aefc17f-c5b5-442a-b7c3-0e927ff2ca10",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    density_eigen = np.load('Eigenvalues/'+eig_file_name+'_eigen.npy')\n",
    "    density_weight = np.load('Eigenvalues/'+eig_file_name+'_weight.npy')\n",
    "except:\n",
    "    hessian_comp = hessian(model, criterion, data=(inputs, targets), cuda=False, model_name = model_name)\n",
    "    density_eigen, density_weight = hessian_comp.density(iter=100, n_v=1)\n",
    "    np.save('Eigenvalues/'+eig_file_name+'_eigen.npy', density_eigen)\n",
    "    np.save('Eigenvalues/'+eig_file_name+'_weight.npy', density_weight)\n",
    "\n",
    "get_esd_plot(density_eigen, density_weight,'plots/eig_'+eig_file_name+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4aed62-3723-4b7d-be55-d4eeea72b5f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# AttentionGru for imdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763402f4-a49f-4c31-8b24-e485cf87d995",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loss landscape plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3c10da-42c9-4bee-bc49-936a5b153da5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### With SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c518f64b-dabe-42ac-b61a-febc4578a5bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "Generate surface file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a629053a-1554-4c15-b4cc-31055e648cb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run plot_surface.py for trained model\n",
    "# !python plot_surface.py --model AttentionGru --dataset imdb --x=-1:1:3 --y=-1:1:3 --model_file to_plot/model_imdb_SGD.pt --dir_type weights --xnorm filter --xignore biasbn --ynorm filter --yignore biasbn --plot --percentage=0.05 --batch_size=16 --loss_name smooth_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7eae910-28d5-47a5-b3ec-17313c3a6a7d",
   "metadata": {
    "tags": []
   },
   "source": [
    "Generate plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9dd0ba9-751f-4313-80b0-b224adaf0cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "plot_2d_contour\n",
      "------------------------------------------------------------------\n",
      "len(xcoordinates): 3   len(ycoordinates): 3\n",
      "[[0.36772302 0.37724695 0.47128022]\n",
      " [0.36875239 0.36698774 0.39151391]\n",
      " [0.38017842 0.38429436 0.36803225]]\n"
     ]
    }
   ],
   "source": [
    "surf_file = 'to_plot/model_imdb_SGD.pt_weights_xignore=biasbn_xnorm=filter_yignore=biasbn_ynorm=filter.h5_[-1.0,1.0,3]x[-1.0,1.0,3].h5'\n",
    "\n",
    "plot_2d_contour(surf_file, 'train_loss', 0.1, 10, 0.5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd20cab6-5923-4511-99e6-c4a19b2aa3e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### With SAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3688bfd5-bc8a-4cff-b018-c86c0fc98a78",
   "metadata": {
    "tags": []
   },
   "source": [
    "Generate surface file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d702612-9152-4bca-9c07-434c1f839c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run plot_surface.py for trained model\n",
    "# !python plot_surface.py --model AttentionGru --dataset imdb --x=-1:1:2 --y=-1:1:2 --model_file to_plot/model_cifar_SAM_rho1.pt --dir_type weights --xnorm filter --xignore biasbn --ynorm filter --yignore biasbn --plot --percentage=0.3 --batch_size=16 --loss_name smooth_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e23c3e-22aa-4bd4-8537-1f20a69f2f0f",
   "metadata": {},
   "source": [
    "Generate plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be2dcad-aa00-4d2b-821c-37607c29532e",
   "metadata": {},
   "outputs": [],
   "source": [
    "surf_file = \n",
    "\n",
    "plot_2d_contour(surf_file, 'train_loss', 0.1, 10, 0.5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080cad5e-9e61-46fc-944c-8767046096ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Eigenvalues of hessian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38edd19-2f67-43a1-8eb5-b8ac1fc600c3",
   "metadata": {},
   "source": [
    "Load trained model and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7cd6260-bcd9-4935-bf7f-731994321b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'AttentionGru'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c3c31cd-f7be-4392-955f-48c3d4b3946d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading aclImdb_v1.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".data\\imdb\\aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:17<00:00, 4.83MB/s]\n",
      ".vector_cache\\glove.6B.zip: 862MB [02:53, 4.98MB/s]                               \n",
      "100%|█████████▉| 399999/400000 [01:13<00:00, 5411.46it/s]\n"
     ]
    }
   ],
   "source": [
    "# get dataset \n",
    "dataset = Imdb(0.05, 16, 2, device)\n",
    "trainloader = dataset.train_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0066bfa-d5cf-499b-b43f-7a2887bff794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([571, 16]) torch.Size([16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_batches = 1 # Only one batch\n",
    "\n",
    "inputs = None\n",
    "targets = None\n",
    "\n",
    "for ind, data in enumerate(trainloader):\n",
    "    inp = data.text.to(device)\n",
    "    tar = data.label.to(device).long()\n",
    "\n",
    "    if inputs is None:\n",
    "        inputs = inp\n",
    "        targets = tar\n",
    "    elif inputs is not None and ind < num_batches:\n",
    "        inputs = torch.cat((inp, data), 0)\n",
    "        targets = torch.cat((targets, tar))\n",
    "    else:\n",
    "        break\n",
    "\n",
    "[print(inputs.size(), targets.size()) if targets is not None else print(inputs.size())]\n",
    "\n",
    "# we use cuda to make the computation fast\n",
    "# model = model.cuda()\n",
    "# inputs, targets = inputs.cuda(), targets.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9718db-59fc-4f6f-83f3-401308a18b41",
   "metadata": {},
   "source": [
    "### With SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a784586-67de-4085-9d83-79ffdd1f6478",
   "metadata": {},
   "outputs": [],
   "source": [
    "stored = torch.load('to_plot/model_imdb_SGD.pt', map_location=lambda storage, loc: storage)\n",
    "\n",
    "vocab_dim = len(dataset.TEXT.vocab)\n",
    "model = AttentionGru(vocab_dim, embedding_dim=300, hidden_dim=32, output_dim=2, num_layers=2, d_rate=0.4)\n",
    "\n",
    "if 'state_dict' in stored.keys():\n",
    "    model.load_state_dict(stored['state_dict'])\n",
    "else:\n",
    "    model.load_state_dict(stored)\n",
    "model.eval()\n",
    "\n",
    "criterion = mean_smooth_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59f09c4-602f-4980-b083-73a351dcf594",
   "metadata": {},
   "source": [
    "Create the hessian computation module and compute eigenvalue density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef5ef4c2-8d13-440b-9baf-d24003ac3946",
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_file_name = 'attentiongru_sgd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4527975c-bcde-424c-9e1b-9b4008ed7c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0\n",
      "Iter 1\n",
      "Iter 2\n",
      "Iter 3\n",
      "Iter 4\n",
      "Iter 5\n",
      "Iter 6\n",
      "Iter 7\n",
      "Iter 8\n",
      "Iter 9\n",
      "Iter 10\n",
      "Iter 11\n",
      "Iter 12\n",
      "Iter 13\n",
      "Iter 14\n",
      "Iter 15\n",
      "Iter 16\n",
      "Iter 17\n",
      "Iter 18\n",
      "Iter 19\n",
      "Iter 20\n",
      "Iter 21\n",
      "Iter 22\n",
      "Iter 23\n",
      "Iter 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franc\\Desktop\\Francesco\\EPFL_Courses\\Optimization for ML\\sharpness-aware_minimization\\loss_landscape\\my_pyhessian\\density_plot.py:64: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  density_output[i, j] = np.sum(tmp_result * weights[i, :])\n",
      "C:\\Users\\franc\\anaconda3\\envs\\ml\\lib\\site-packages\\matplotlib\\cbook\\__init__.py:1335: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return np.asarray(x, float)\n",
      "C:\\Users\\franc\\anaconda3\\envs\\ml\\lib\\site-packages\\matplotlib\\transforms.py:2860: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  vmin, vmax = map(float, [vmin, vmax])\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    density_eigen = np.load('Eigenvalues/'+eig_file_name+'_eigen.npy')\n",
    "    density_weight = np.load('Eigenvalues/'+eig_file_name+'_weight.npy')\n",
    "\n",
    "except:\n",
    "    hessian_comp = hessian(model, criterion, data=(inputs, targets), cuda=False, model_name = model_name)\n",
    "    density_eigen, density_weight = hessian_comp.density(iter=25, n_v=1)\n",
    "    np.save('Eigenvalues/'+eig_file_name+'_eigen.npy', density_eigen)\n",
    "    np.save('Eigenvalues/'+eig_file_name+'_weight.npy', density_weight)\n",
    "    \n",
    "get_esd_plot(density_eigen, density_weight,'plots/eig_'+eig_file_name+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a07122-50c4-4cf6-affc-8a6401306b76",
   "metadata": {},
   "source": [
    "### With SAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1a0061df-ffb2-49a8-babf-235c9fe19d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "stored = torch.load('to_plot/model_imdb_SAM_rho????.pt', map_location=lambda storage, loc: storage)\n",
    "\n",
    "vocab_dim = len(dataset.TEXT.vocab)\n",
    "model = AttentionGru(vocab_dim, embedding_dim=300, hidden_dim=32, output_dim=2, num_layers=2, d_rate=0.4)\n",
    "\n",
    "if 'state_dict' in stored.keys():\n",
    "    model.load_state_dict(stored['state_dict'])\n",
    "else:\n",
    "    model.load_state_dict(stored)\n",
    "model.eval()\n",
    "\n",
    "criterion = mean_smooth_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ecc0c8-2ba9-4a29-b879-68d7f19e6f1b",
   "metadata": {},
   "source": [
    "Create the hessian computation module and compute eigenvalue density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfda9f0-ee2d-43b0-bb60-e2986bc64eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_file_name = 'attentiongru_sam'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e791fa-4568-49b2-8724-ef0683bc49f1",
   "metadata": {},
   "source": [
    "Plot eigenvalue density and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0c163398-0335-4f78-959c-5292b5fed924",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    density_eigen = np.load('Eigenvalues/'+eig_file_name+'_eigen.npy')\n",
    "    density_weight = np.load('Eigenvalues/'+eig_file_name+'_weight.npy')\n",
    "except:\n",
    "    hessian_comp = hessian(model, criterion, data=(inputs, targets), cuda=False, model_name = model_name)  \n",
    "    density_eigen, density_weight = hessian_comp.density(iter=100, n_v=1)\n",
    "    np.save('Eigenvalues/'+eig_file_name+'_eigen.npy', density_eigen)\n",
    "    np.save('Eigenvalues/'+eig_file_name+'_weight.npy', density_weight)\n",
    "    \n",
    "get_esd_plot(density_eigen, density_weight,'plots/eig_'+eig_file_name+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e2e302-872b-45a9-9307-21cdfbf7d2f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Graph Convolutional Network for Mutagenicity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f34f202-3201-4e61-b63a-40c5c1182536",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loss landscape plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0c92a5-3940-41ea-8203-1cb6018e884d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### With ADAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a359c38-6408-4172-a265-04626f2cc43f",
   "metadata": {
    "tags": []
   },
   "source": [
    "Generate surface file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fd6ee7-f098-41ef-90ae-2abb4bdc40fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run plot_surface.py for trained model\n",
    "# !python plot_surface.py --model GCN --dataset Mutagenicity --x=-1:1:3 --y=-1:1:3 --model_file to_plot/model_gcn_ADAM.pt --dir_type weights --xnorm filter --xignore biasbn --ynorm filter --yignore biasbn --plot --batch_size=64 --loss_name smooth_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529226c7-de17-49b4-bfef-c102d9751d2f",
   "metadata": {
    "tags": []
   },
   "source": [
    "Generate plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "75f51cd0-a618-41b6-b0cd-fd933e2d29a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "plot_2d_contour\n",
      "------------------------------------------------------------------\n",
      "len(xcoordinates): 3   len(ycoordinates): 3\n",
      "[[3.08615565 1.17431903 1.04388905]\n",
      " [0.79135042 0.28873381 0.32784745]\n",
      " [0.44603446 0.33184609 0.39543769]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franc\\Desktop\\Francesco\\EPFL_Courses\\Optimization for ML\\sharpness-aware_minimization\\loss_landscape\\plot_2D.py:87: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "surf_file = 'to_plot/model_gcn_ADAM.pt_weights_xignore=biasbn_xnorm=filter_yignore=biasbn_ynorm=filter.h5_[-1.0,1.0,3]x[-1.0,1.0,3].h5'\n",
    "\n",
    "plot_2d_contour(surf_file, 'train_loss', 0.1, 10, 0.5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5c8051-80f9-4929-9cb0-d24254e518b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### With SAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707fd6e4-509f-4179-b6e2-50359bda37b1",
   "metadata": {
    "tags": []
   },
   "source": [
    "Generate surface file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55bc3c7-dc14-484d-8e80-17c66c7639b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run plot_surface.py for trained model\n",
    "# !python plot_surface.py --model GCN --dataset Mutagenicity --x=-1:1:2 --y=-1:1:2 --model_file to_plot/model_gcn_SAM_rho0.3.pt --dir_type weights --xnorm filter --xignore biasbn --ynorm filter --yignore biasbn --plot --batch_size=64 --loss_name smooth_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8c40ba-9d90-4e0c-a7bc-28c89a96155d",
   "metadata": {},
   "source": [
    "Generate plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8ac361-6637-4b74-a91a-11d9bb9b03ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "surf_file = 'to_plot/model_cifar_halfSAM_rho05.pt_weights_xignore=biasbn_xnorm=filter_yignore=biasbn_ynorm=filter.h5_[-1.0,1.0,5]x[-1.0,1.0,5].h5'\n",
    "\n",
    "plot_2d_contour(surf_file, 'train_loss', 0.1, 10, 0.5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5e2084-8f78-4e32-8cfa-bf505538ad1e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Eigenvalues of hessian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0563947f-e751-4911-9d80-a251a44d71fb",
   "metadata": {},
   "source": [
    "Load trained model and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ba09a2ac-b234-48d3-a690-cc3bf9a013c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'GCN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0df5efbc-8f6b-499b-a493-686471518e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataset \n",
    "dataset = GraphDataset('Mutagenicity', 70, 64)\n",
    "trainloader = dataset.train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "aacac0e7-5478-4e47-b450-d0eaee61786f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1698, 1698)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_batches = 1\n",
    "\n",
    "inputs = None\n",
    "targets = None\n",
    "\n",
    "for ind, data in enumerate(trainloader):\n",
    "    if inputs is None:\n",
    "        inputs = data\n",
    "    elif inputs is not None and ind < num_batches:\n",
    "        inputs = torch.cat((inputs, data), 0)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "[print(inputs.size(), targets.size()) if targets is not None else print(inputs.size())]\n",
    "\n",
    "# we use cuda to make the computation fast\n",
    "# model = model.cuda()\n",
    "# inputs, targets = inputs.cuda(), targets.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9d2d8f-eb38-40d0-aa3c-cf3a869018a8",
   "metadata": {},
   "source": [
    "### With SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c5d67627-81c7-4197-87b3-7eee78d14190",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(64, dataset.dataset.num_node_features, dataset.dataset.num_classes).to(device)\n",
    "stored = torch.load('to_plot/model_gcn_ADAM.pt', map_location=lambda storage, loc: storage)\n",
    "\n",
    "if 'state_dict' in stored.keys():\n",
    "    model.load_state_dict(stored['state_dict'])\n",
    "else:\n",
    "    model.load_state_dict(stored)\n",
    "model.eval()\n",
    "\n",
    "criterion = mean_smooth_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f85ec50-aa48-426f-803a-eede0d340b6b",
   "metadata": {},
   "source": [
    "Create the hessian computation module and compute eigenvalue density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a431c651-fb89-4e0e-9552-6cbe4db4a6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_file_name = 'gcn_adam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "77a1145e-37ea-4cb4-8831-6c4e206f3af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    density_eigen = np.load('Eigenvalues/'+eig_file_name+'_eigen.npy')\n",
    "    density_weight = np.load('Eigenvalues/'+eig_file_name+'_weight.npy')\n",
    "except:\n",
    "    hessian_comp = hessian(model, criterion, data=(inputs, targets), cuda=False, model_name = model_name)\n",
    "    density_eigen, density_weight = hessian_comp.density(iter=100, n_v=1)\n",
    "    np.save('Eigenvalues/'+eig_file_name+'_eigen.npy', density_eigen)\n",
    "    np.save('Eigenvalues/'+eig_file_name+'_weight.npy', density_weight)\n",
    "\n",
    "get_esd_plot(density_eigen, density_weight,'plots/eig_'+eig_file_name+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bf5459-e4fd-4a4e-bf09-972f640e7b15",
   "metadata": {},
   "source": [
    "### With SAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7f518ab9-c92a-448b-b5f2-344573a69190",
   "metadata": {},
   "outputs": [],
   "source": [
    "stored = torch.load('to_plot/model_gcn_SAM_rho0.3.pt', map_location=lambda storage, loc: storage)\n",
    "model = GCN(64, dataset.dataset.num_node_features, dataset.dataset.num_classes).to(device)\n",
    "\n",
    "if 'state_dict' in stored.keys():\n",
    "    model.load_state_dict(stored['state_dict'])\n",
    "else:\n",
    "    model.load_state_dict(stored)\n",
    "model.eval()\n",
    "\n",
    "criterion = mean_smooth_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc0f920-3581-4617-94ba-62b7866cff6d",
   "metadata": {},
   "source": [
    "Create the hessian computation module and compute eigenvalue density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b5470548-56c9-4c8b-aeb9-ad8c4548ac23",
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_file_name = 'gcn_sam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f8e4ede1-3083-4097-bdc4-9808312df750",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    density_eigen = np.load('Eigenvalues/'+eig_file_name+'_eigen.npy')\n",
    "    density_weight = np.load('Eigenvalues/'+eig_file_name+'_weight.npy')\n",
    "except:\n",
    "    hessian_comp = hessian(model, criterion, data=(inputs, targets), cuda=False, model_name = model_name)\n",
    "    density_eigen, density_weight = hessian_comp.density(iter=100, n_v=1)\n",
    "    np.save('Eigenvalues/'+eig_file_name+'_eigen.npy', density_eigen)\n",
    "    np.save('Eigenvalues/'+eig_file_name+'_weight.npy', density_weight)\n",
    "    \n",
    "get_esd_plot(density_eigen, density_weight,'plots/eig_'+eig_file_name+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a2f14c-8b62-4316-83a6-12657b06d389",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Old Eigenvalues of hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "837db404-bbdb-44f2-aae5-86855b46fe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "from torchvision import datasets, transforms\n",
    "# from pytorchcv.model_provider import get_model as ptcv_get_model # model\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eaa412c4-62bc-4979-9434-fab397bf40e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_pyhessian import hessian, utils# Hessian computation\n",
    "from my_pyhessian.density_plot import get_esd_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b443c931-22d6-4b9b-9a39-f26ef6fdae95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append(\"..\")\n",
    "from models.smooth_cross_entropy import mean_smooth_crossentropy\n",
    "from models.wide_res_net import WideResNet\n",
    "from models.attention_gru import AttentionGru\n",
    "from models.gcn import GCN\n",
    "\n",
    "from DatasetClass.cifar import Cifar\n",
    "from DatasetClass.imdb import Imdb\n",
    "from DatasetClass.TUD import GraphDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e36145-d8d7-47c9-89bf-5193c158f4ef",
   "metadata": {},
   "source": [
    "Load trained model and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0b538420-8eb8-4738-9c14-d7e108898433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'WideResNet'\n",
    "# model_name = 'AttentionGru'\n",
    "model_name = 'GCN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e3e0ab7e-5779-4ad3-9adb-a453d9fe77d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataset \n",
    "if model_name == 'WideResNet':\n",
    "    dataset = Cifar(0.3, 128, 2)\n",
    "    trainloader, testloader = dataset.train, dataset.test\n",
    "elif model_name == 'AttentionGru':\n",
    "    dataset = Imdb(0.3, 16, 2, device)\n",
    "    trainloader = dataset.train_iterator\n",
    "\n",
    "elif model_name == 'GCN':\n",
    "    dataset = GraphDataset('Mutagenicity', 70, 64)\n",
    "    trainloader = dataset.train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "48e635e0-1d1a-43ee-86e7-2d23bfbcbc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stored = torch.load('../to_plot/model_cifar_SGD.pt', map_location=lambda storage, loc: storage)\n",
    "# stored = torch.load('../to_plot/model_cifar_halfSAM_rho0.5.pt', map_location=lambda storage, loc: storage)\n",
    "model = WideResNet(8, 2, 0.0, in_channels=3, labels=10)\n",
    "\n",
    "model = GCN(64, dataset.dataset.num_node_features, dataset.dataset.num_classes).to(device)\n",
    "stored = torch.load('../to_plot/model_gcn_ADAM.pt', map_location=lambda storage, loc: storage)\n",
    "\n",
    "\n",
    "if 'state_dict' in stored.keys():\n",
    "    model.load_state_dict(stored['state_dict'])\n",
    "else:\n",
    "    model.load_state_dict(stored)\n",
    "model.eval()\n",
    "\n",
    "criterion = mean_smooth_crossentropy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7d4f6b-8d2d-4435-949f-9d23bb132f88",
   "metadata": {},
   "source": [
    "Extract batches of data for computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1a5742df-a1b2-4acd-b615-f9bfc3b54b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1908, 1908)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_batches = 1\n",
    "\n",
    "inputs = None\n",
    "targets = None\n",
    "\n",
    "# FOR CIFAR\n",
    "if model_name == 'WideResNet':\n",
    "    for ind, (data, tar) in enumerate(trainloader):\n",
    "        if inputs is None:\n",
    "            inputs = data\n",
    "            targets = tar\n",
    "        elif inputs is not None and ind < num_batches:\n",
    "            inputs = torch.cat((inputs, data), 0)\n",
    "            targets = torch.cat((targets, tar))\n",
    "        else:\n",
    "            break\n",
    "\n",
    "# FOR IMDB\n",
    "elif model_name == 'AttentionGru':\n",
    "    for ind, data in enumerate(trainloader):\n",
    "        inp = data.text.to(device)\n",
    "        tar = data.label.to(device).long()\n",
    "\n",
    "        if inputs is None:\n",
    "            inputs = data\n",
    "            targets = tar\n",
    "        elif inputs is not None and ind < num_batches:\n",
    "            inputs = torch.cat((inputs, data), 0)\n",
    "            targets = torch.cat((targets, tar))\n",
    "        else:\n",
    "            break\n",
    "\n",
    "# FOR GCN\n",
    "elif model_name == 'GCN':\n",
    "    for ind, data in enumerate(trainloader):\n",
    "        if inputs is None:\n",
    "            inputs = data\n",
    "        elif inputs is not None and ind < num_batches:\n",
    "            inputs = torch.cat((inputs, data), 0)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "[print(inputs.size(), targets.size()) if targets is not None else print(inputs.size())]\n",
    "\n",
    "# we use cuda to make the computation fast\n",
    "# model = model.cuda()\n",
    "# inputs, targets = inputs.cuda(), targets.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2efd2e-5114-4a09-9e1e-255c7d78dfbb",
   "metadata": {},
   "source": [
    "Create the hessian computation module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bdb5d6eb-dbc8-4945-81a6-86efd6345d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franc\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\autograd\\__init__.py:200: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\engine.cpp:1156.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    }
   ],
   "source": [
    "hessian_comp = hessian(model, criterion, data=(inputs, targets), cuda=False, model_name = model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f156d40-6f48-4a55-85a5-9b5fe5a2df4e",
   "metadata": {},
   "source": [
    "Compute eigenvalue density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192f91f8-5d0e-450d-a084-b9d8da843a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE !!!\n",
    "eig_file_name = 'gcn_sgd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c1426e-4da4-4aff-a8ef-2c405672fe81",
   "metadata": {},
   "outputs": [],
   "source": [
    "density_eigen, density_weight = hessian_comp.density(iter=100, n_v=1)\n",
    "np.save('Eigenvalues/'+eig_file_name+'_eigen.npy', density_eigen)\n",
    "np.save('Eigenvalues/'+eig_file_name+'_weight.npy', density_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc431ee-e1a6-4af5-9d57-4813c1e3534c",
   "metadata": {},
   "source": [
    "Plot eigenvalue density and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4281a310-b4de-40b9-bb52-366d3ddbfa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "density_eigen = np.load('Eigenvalues/'+eig_file_name+'_eigen.npy')\n",
    "density_weight = np.load('Eigenvalues/'+eig_file_name+'_weight.npy')\n",
    "\n",
    "get_esd_plot(density_eigen, density_weight,'plots/eig_'+eig_file_name+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a293956a-9059-49ed-87b2-b66d647818de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top Hessian eigenvalue of this model is 15.2096\n"
     ]
    }
   ],
   "source": [
    "# Compute the top eigenvalue.\n",
    "top_eigenvalues, top_eigenvector = hessian_comp.eigenvalues(maxIter=10, top_n = 1)\n",
    "print(\"The top Hessian eigenvalue of this model is %.4f\"%top_eigenvalues[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103e2c64-7e71-4904-9816-ae102bc66da9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a69b12e-3e53-4eee-b7cd-d30079aa9621",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
